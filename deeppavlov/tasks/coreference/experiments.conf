# Word embeddings.
glove_300d {
  path = glove.840B.300d.txt
  size = 300
  format = txt
  lowercase = false
}
glove_300d_filtered {
  path = glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}
turian_50d {
  path = turian.50d.txt
  size = 50
  format = txt
  lowercase = false
}
w2v_50d_filt {
  path = ./data/w2v_50d.filtered.txt
  size = 50
  format = txt
  lowercase = false
}
w2v_50d {
  path = ./data/w2v_50d.txt
  size = 50
  format = txt
  lowercase = false
}
ft {
  path = ./data/embeddings_lenta.vec
  size = 100
  format = vec
  lowercase = false
}

# Compute clusters.
nlp {
  addresses {
    ps = [nlp2:2222]
    worker = [n01:2222, n02:2222, n03:2222, n04:2222, n05:2222, n07:2222, n08:2222, n09:2222, n10:2222, n11:2222, n12:2222, n13:2222, n14:2222, n15:2222, n16:2222]
  }
  gpus = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
}
appositive {
  addresses {
    ps = [localhost:2222]
    worker = [localhost:2223, localhost:2224]
  }
  gpus = [0, 1]
}

# Main configuration
best {
  #computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  mention_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "char_vocab.english.txt"
  embeddings = [${glove_300d_filtered}, ${turian_50d}]
  lstm_size = 200
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_mention_width = 10
  use_metadata = true
  use_features = true
  model_heads = true

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  # Other.
  train_path = train.english.jsonlines
  eval_path = dev.english.jsonlines
  conll_eval_path = dev.english.v4_auto_conll
  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}
}

main_r {
  # Computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  mention_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "./vocab/char_vocab.russian.txt"
  embeddings = [${w2v_50d_filt}]
  lstm_size = 200
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_mention_width = 10
  use_metadata = true
  use_features = true
  model_heads = true

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  # Other.
  train_path = ./data/new/train.russian.jsonlines
  eval_path = ./data/new/dev.russian.jsonlines
  conll_eval_path = ./my_conll/new/dev.russian.v4_conll
  genres = [bc]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}
}


# Multiple full models for ensembling.
best0 = ${best}
best1 = ${best}
best2 = ${best}
best3 = ${best}
best4 = ${best}

# Ablations.
glove = ${best} {
  embeddings = [${glove_300d_filtered}]
}
turian = ${best} {
  embeddings = [${turian_50d}]
}
w2v = ${main_r} {
  embeddings = [${w2v_50d_filt}]
}
fasttext = ${main_r} {
  embeddings = [${ft}]
}
nochar = ${main_r} {
  char_embedding_size = -1
  embeddings = [${w2v_50d}]
}
nometa = ${main_r} {
  use_metadata = false
  embeddings = [${w2v_50d}]
}
noheads = ${main_r} {
  model_heads = false
  embeddings = [${w2v_50d}]
}
nofeatures = ${main_r} {
  use_features = false
  embeddings = [${w2v_50d}]
}
noch-me-fs = ${main_r} {
  use_features = false
  use_metadata = false
  char_embedding_size = -1
  embeddings = [${w2v_50d}]
}
# For evaluation. Do not use for training (i.e. only for decoder.py, ensembler.py, visualize.py and demo.py). Rename `best0` directory to `final`.
final = ${main_r} {
  embeddings = [${w2v_50d}]
  eval_path = ./data/new/test.russian.jsonlines
  conll_eval_path = ./my_conll/new/test.russian.v4_conll
}
final_ft = ${main_r} {
  embeddings = [${ft}]
  eval_path = ./data/new/test.russian.jsonlines
  conll_eval_path = ./my_conll/new/test.russian.v4_conll
}
